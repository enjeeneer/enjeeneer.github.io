<!DOCTYPE html>
<html lang="en">
    <head>
        <meta charset="UTF-8">
<meta http-equiv="X-UA-Compatible" content="ie=edge">
<meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
<meta name="author" content="Scott Jeen">
<meta name="description" content="I was fortunate to attend NeurIPS in New Orleans in November. Here, I publish my takeaways to give you a feel for the zeitgeist. I’ll discuss, firstly, the papers, then the workshops, and finally, and briefly, the keynotes.
Papers Here’s a ranked list of my top 8 papers. Most are on Offline RL, which is representative of the conference writ large.
1. Does Zero-Shot Reinforcement Learning Exist (Touati et. al, 2022)" />
<meta name="keywords" content="Scott Jeen" />
<meta name="robots" content="noodp" />
<meta name="theme-color" content="#6B8E23" />
<link rel="canonical" href="https://enjeeneer.io/posts/2023/01/neurips-2022/" />


<script type="application/javascript">
var doNotTrack = false;
if (!doNotTrack) {
	(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
	(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
	m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
	})(window,document,'script','https://www.google-analytics.com/analytics.js','ga');
	ga('create', 'UA-192648932-1', 'auto');
	
	ga('send', 'pageview');
}
</script>


    <title>
        
            NeurIPS 2022 :: Scott Jeen  — real world reinforcement learning
        
    </title>



<link href="https://cdnjs.cloudflare.com/ajax/libs/flag-icon-css/3.5.0/css/flag-icon.min.css" rel="stylesheet"
    type="text/css">



<link rel="stylesheet" href="https://enjeeneer.io/main.cbec4bded5981a9639be0a9253dbc5636fb308fba08c31a50670aee0a034a132.css">




    <link rel="apple-touch-icon" sizes="180x180" href="https://enjeeneer.io/apple-touch-icon.png">
    <link rel="icon" type="image/png" sizes="32x32" href="https://enjeeneer.io/favicon-32x32.png">
    <link rel="icon" type="image/png" sizes="16x16" href="https://enjeeneer.io/favicon-16x16.png">
    <link rel="manifest" href="https://enjeeneer.io/site.webmanifest">
    <link rel="mask-icon" href="https://enjeeneer.io/safari-pinned-tab.svg" color="#6B8E23">
    <link rel="shortcut icon" href="https://enjeeneer.io/favicon.ico">
    <meta name="msapplication-TileColor" content="#6B8E23">
    <meta name="theme-color" content="#6B8E23">



<meta itemprop="name" content="NeurIPS 2022">
<meta itemprop="description" content="I was fortunate to attend NeurIPS in New Orleans in November. Here, I publish my takeaways to give you a feel for the zeitgeist. I’ll discuss, firstly, the papers, then the workshops, and finally, and briefly, the keynotes.
Papers Here’s a ranked list of my top 8 papers. Most are on Offline RL, which is representative of the conference writ large.
1. Does Zero-Shot Reinforcement Learning Exist (Touati et. al, 2022)"><meta itemprop="datePublished" content="2023-01-26T21:08:05+00:00" />
<meta itemprop="dateModified" content="2023-01-26T21:08:05+00:00" />
<meta itemprop="wordCount" content="1779"><meta itemprop="image" content="https://enjeeneer.io"/>
<meta itemprop="keywords" content="" />
<meta name="twitter:card" content="summary_large_image"/>
<meta name="twitter:image" content="https://enjeeneer.io"/>

<meta name="twitter:title" content="NeurIPS 2022"/>
<meta name="twitter:description" content="I was fortunate to attend NeurIPS in New Orleans in November. Here, I publish my takeaways to give you a feel for the zeitgeist. I’ll discuss, firstly, the papers, then the workshops, and finally, and briefly, the keynotes.
Papers Here’s a ranked list of my top 8 papers. Most are on Offline RL, which is representative of the conference writ large.
1. Does Zero-Shot Reinforcement Learning Exist (Touati et. al, 2022)"/>



    <meta property="og:title" content="NeurIPS 2022" />
<meta property="og:description" content="I was fortunate to attend NeurIPS in New Orleans in November. Here, I publish my takeaways to give you a feel for the zeitgeist. I’ll discuss, firstly, the papers, then the workshops, and finally, and briefly, the keynotes.
Papers Here’s a ranked list of my top 8 papers. Most are on Offline RL, which is representative of the conference writ large.
1. Does Zero-Shot Reinforcement Learning Exist (Touati et. al, 2022)" />
<meta property="og:type" content="article" />
<meta property="og:url" content="https://enjeeneer.io/posts/2023/01/neurips-2022/" /><meta property="og:image" content="https://enjeeneer.io"/><meta property="article:section" content="posts" />
<meta property="article:published_time" content="2023-01-26T21:08:05+00:00" />
<meta property="article:modified_time" content="2023-01-26T21:08:05+00:00" />







    <meta property="article:published_time" content="2023-01-26 21:08:05 &#43;0000 UTC" />








<script src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script>
    <script id="MathJax-script" async src="https://cdn.jsdelivr.net/npm/mathjax@3.0.1/es5/tex-mml-chtml.js"></script>

    
    </head>

    <body class="">
        <div class="container">
            <header class="header">
    
<script type="application/javascript">
var doNotTrack = false;
if (!doNotTrack) {
	(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
	(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
	m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
	})(window,document,'script','https://www.google-analytics.com/analytics.js','ga');
	ga('create', 'UA-192648932-1', 'auto');
	
	ga('send', 'pageview');
}
</script>
    <span class="header__inner">
        <a href="https://enjeeneer.io/" style="text-decoration: none;">
    <div class="logo">
        
            <span class="logo__mark">></span>
            <span class="logo__text">/enjeeneer/</span>
            <span class="logo__cursor" style=
                  "
                   background-color:#6B8E23;
                   animation-duration:1s;">
            </span>
        
    </div>
</a>


        <span class="header__right">
            
                <nav class="menu">
    <ul class="menu__inner"><li><a href="https://enjeeneer.io/about/">about</a></li><li><a href="https://enjeeneer.io/cv/cv-jul23-coffee.pdf">cv</a></li><li><a href="https://enjeeneer.io/posts/">posts</a></li><li><a href="https://enjeeneer.io/projects/">projects</a></li><li><a href="https://scholar.google.com/citations?user=3HPX720AAAAJ&amp;hl=en&amp;oi=ao">scholar</a></li><li><a href="https://enjeeneer.io/talks/">talks</a></li>
    </ul>
</nav>

                <span class="menu-trigger">
                    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24">
                        <path d="M0 0h24v24H0z" fill="none"/>
                        <path d="M3 18h18v-2H3v2zm0-5h18v-2H3v2zm0-7v2h18V6H3z"/>
                    </svg>
                </span>
            

            <span class="theme-toggle unselectable"><svg class="theme-toggler" width="24" height="24" viewBox="0 0 48 48" fill="none" xmlns="http://www.w3.org/2000/svg">
  <path d="M22 41C32.4934 41 41 32.4934 41 22C41 11.5066 32.4934 3 22
  3C11.5066 3 3 11.5066 3 22C3 32.4934 11.5066 41 22 41ZM7 22C7
  13.7157 13.7157 7 22 7V37C13.7157 37 7 30.2843 7 22Z"/>
</svg>
</span>
        </span>
    </span>
</header>


            <div class="content">
                
  <main class="post">

    <div class="post-info">
      <p>
        <svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="feather feather-clock">
          <circle cx="12" cy="12" r="10"></circle>
          <polyline points="12 6 12 12 16 14"></polyline>
        </svg>
        9 minutes

        
      </p>
    </div>

    <article>
      <h1 class="post-title">
        <a href="https://enjeeneer.io/posts/2023/01/neurips-2022/">NeurIPS 2022</a>
      </h1>

      

      <div class="post-content">
        <p>I was fortunate to attend NeurIPS in New Orleans in November. Here, I publish my takeaways to give you a feel for the zeitgeist. I’ll discuss, firstly, the papers, then the workshops, and finally, and briefly, the keynotes.</p>
<h2 id="papers">Papers</h2>
<p>Here’s a ranked list of my top 8 papers. Most are on Offline RL, which is representative of the conference writ large.</p>
<p><strong>1. <a href="https://arxiv.org/pdf/2209.14935.pdf">Does Zero-Shot Reinforcement Learning Exist (Touati et. al, 2022)</a></strong></p>
<figure><img src="https://enjeeneer.io/img/toutati2022.jpg"/>
</figure>

<p><strong>Key idea.</strong> To do zero-shot RL, we need to learn a general function from reward-free transitions that implicitly encodes the trajectories of <strong>all</strong> optimal policies for <strong>all</strong> tasks. The authors propose to learn two functions: \(F_\theta(s)\) and  \(B_\phi(s)\) that encode the future and past of state \(s\). We want to learn functions that <strong>always</strong> find a route from \(s \rightarrow s'\).</p>
<p><strong>Implication(s):</strong></p>
<ul>
<li>They beat all previous zero-shot RL algorithms on the standard offline RL tasks, and approach the performance of online, reward-guided RL algorithms in some envs.</li>
</ul>
<p><strong>Misc thoughts:</strong></p>
<ul>
<li>It seems clear that zero-shot RL is the route to real world deployment for RL. This work represents the best effort I’ve seen in this direction. I’m really excited by it and will be looking to extend it in my own future work.</li>
</ul>
<hr>
<p><strong>2. <a href="https://arxiv.org/pdf/2206.05314.pdf">Large Scale Retrieval for Reinforcement Learning (Humphreys et. al, 2022)</a></strong></p>
<figure><img src="https://enjeeneer.io/img/largescaleretrieval.png" width="500" height="600"/>
</figure>

<p><strong>Key idea.</strong> Assuming access to a large offline dataset, we perform a nearest neighbours search over the dataset w.r.t. the current state, and append the retrieved states, next actions, rewards and final states (in the case of go) to the current state. The policy then acts w.r.t this augmented state.</p>
<p>Implication(s):</p>
<ul>
<li><strong>Halves</strong> compute required to achieve the baseline win-rate in Go.</li>
</ul>
<p><strong>Misc thoughts:</strong></p>
<ul>
<li>This represents the most novel approach to offline RL I’ve seen; most techniques separate the offline and online learning phases, but here the authors combine them elegantly.</li>
<li>To me this feels like a far more promising approach to offline RL than CQL etc.</li>
</ul>
<hr>
<p><strong>3. <a href="https://arxiv.org/pdf/2206.00730.pdf">The Phenomenon of Policy Churn (Schaul et. al, 2022)</a></strong></p>
<p><figure><img src="https://enjeeneer.io/img/churn1.png"/>
</figure>

<figure><img src="https://enjeeneer.io/img/churn2.png"/>
</figure>
</p>
<p><strong>Key idea.</strong> When a value-based agent acts greedily, the policy updates by a surprising amount per gradient step e.g. in up to 10% of states in some cases.</p>
<p><strong>Implication(s):</strong></p>
<ul>
<li>Policy churn means that ((\epsilon))-greedy exploration may not be required as a rapidly changing policy induces enough noise into the data distribution that exploration may be implicit.</li>
</ul>
<p><strong>Misc thoughts:</strong></p>
<ul>
<li>Their paper is structured in a really engaging way.</li>
<li>I liked their ML researcher survey which quantified how surprising their result was to experts.</li>
</ul>
<hr>
<p><strong>4. <a href="https://arxiv.org/pdf/2206.08853.pdf">MINEDOJO: Building Open-Ended Embodied Agents with Internet-Scale Knowledge (Fan et. al, 2022)</a></strong></p>
<figure><img src="https://enjeeneer.io/img/minedojo.jpg"/>
</figure>

<p><strong>Key idea.</strong> An internet-scale benchmark for generalist RL agents. 1000s of tasks, and a limitless procedurally-generated world for training.</p>
<p><strong>Implication(s):</strong></p>
<ul>
<li>Provides a sufficiently diverse and complex sandbox for training more generally capable agents.</li>
</ul>
<p><strong>Misc thoughts:</strong></p>
<ul>
<li>This is an amazing feat software development effort from a relatively small team. Jim Fan is so cool!</li>
</ul>
<hr>
<p><strong>5. <a href="https://arxiv.org/pdf/2210.05805.pdf">Exploration via Elliptical Episodic Bonuses (Henaff et. al, 2022)</a></strong></p>
<figure><img src="https://enjeeneer.io/img/ellipticalbonus.png"/>
</figure>

<p><strong>Key Idea.</strong> Guided exploration is often performed by providing the agent reward inversely proportional to the state visitation count i.e. if you haven’t visited this state much you receive added reward. This works for discrete state spaces, but in continuous state spaces each visited state is ~ unique. Here, the authors parameterise ellipses around visited states, specifying a <em>region</em> of nearby states, outside of which the agent receives added reward.</p>
<p><strong>Implication(s):</strong></p>
<ul>
<li>Better exploration means SOTA on the mini-hack suite of envs</li>
<li>Strong performance of reward-free exploration tasks i.e. this is a really good way of thinking about exploration.</li>
</ul>
<p><strong>Misc. thoughts:</strong></p>
<ul>
<li>I really liked the elegance of this idea. A good example of simple, well-examined ideas being useful to the community.</li>
</ul>
<hr>
<p><strong>6. <a href="https://arxiv.org/pdf/2205.15967.pdf">You Can’t Count on Luck: Why Decision Transformers and RvS Fail in Stochastic Environments (Paster et al., 2022)</a></strong></p>
<figure><img src="https://enjeeneer.io/img/luck.png"/>
</figure>

<p><strong>Key Idea.</strong> In a stochastic environment, trajectories in a dataset used to train decision transformer may be high-reward by chance. Here the authors cluster similar trajectories and find their expected reward to mitigate overfitting to lucky trajectories.</p>
<p><strong>Implication(s):</strong></p>
<ul>
<li>Decision transformer trained on these new objectives exhibits policies that area better aligned with the return conditioning of the user.</li>
</ul>
<p><strong>Misc. thoughts:</strong></p>
<ul>
<li>Another simple idea with positive implications for performance.</li>
</ul>
<hr>
<p><strong>7. <a href="https://nips.cc/virtual/2022/poster/52843">Multi-Game Decision Transformers</a> (Lee et al., 2022)</strong></p>
<figure><img src="https://enjeeneer.io/img/multigame.png"/>
</figure>

<p><strong>Key idea.</strong> Instead of predicting just the next action conditioned on state and return-to-go like the original decision transformer paper, they predict the intermediate reward and return-to-go. This allows them to re-condition on new returns-to-go at each timestep, using a clever sampling procedure that samples likely expert returns-to-go.</p>
<p><strong>Implication(s):</strong></p>
<ul>
<li>SOTA on standard atari offline RL tasks.</li>
</ul>
<p><strong>Misc thoughts:</strong></p>
<ul>
<li>This work is very similar to the original decision transformer paper, so I’m surprised that it received a best paper award.</li>
<li>It represents continued progress in the field on offline RL, and more specifically, decision transformer style architectures.</li>
</ul>
<hr>
<p><strong>8. <a href="https://arxiv.org/abs/2206.01079">When does return-conditioned supervised learning work for offline reinforcement learning? (Brandfonbrener, 2022)</a></strong></p>
<p><strong>Key idea.</strong> Much recent work on offline RL can be cast as supervised learning on a near-optimal offline dataset then conditioning on high rewards from the dataset at test time; under what conditions is this a valid approach? Here the authors prove that this (unsurprisingly) only works when two conditions are met: 1) the test envs are (nearly) deterministic, and 2) there is trajectory-level converage in the dataset.</p>
<p><strong>Implication(s):</strong></p>
<ul>
<li>Current approaches to offline RL will not work in the real world because real envs are generally stochastic.</li>
</ul>
<p><strong>Misc thoughts:</strong></p>
<ul>
<li>I liked that the authors proved the community’s intuitions on current approaches to offline RL that, although somewhat obvious in retrospect, had not been verified.</li>
</ul>
<hr>
<h2 id="workshops">Workshops</h2>
<p>I attended 5 workshops:</p>
<ol>
<li>Foundation Models for Decision Making</li>
<li>Safety</li>
<li>Offline RL</li>
<li>Real Life Reinforcement Learning</li>
<li>Tackling Climate Change with Machine Learning</li>
</ol>
<p>I found the latter three to be interesting, but less informative and precient as the first two. I therefore only discuss the Foundation Models for Decision Making and Safety workshops; the extent to which I enjoyed both workshops is, in a sense, oxymoronic.</p>
<h3 id="foundation-models-for-decision-making">Foundation Models for Decision Making</h3>
<p><strong>Leslie P. Kaelbling: What does an intelligent robot need to know?</strong></p>
<figure><img src="https://enjeeneer.io/img/kaelbling2022.jpg"/>
</figure>

<p>My favourite talk was from <a href="https://scholar.google.com/citations?user=IcasIiwAAAAJ&amp;hl=en">Leslie Kaelbling</a> of MIT. Kaelbling focussed on our proclivity for building inductive biases into our models (a similar thesis to Sutton’s <a href="http://www.incompleteideas.net/IncIdeas/BitterLesson.html">Bitter Lesson</a>); though good in short term, the effectiveness of such priors plateaus in the long-run. I agree with her.</p>
<p>She advocates for a marketplace of pre-trained models of the following types:</p>
<ul>
<li>Foundation: space, geometry, kinematics</li>
<li>Psychology: other agents, beliefs, desires etc.</li>
<li>Culture: how do u do things in the world e.g. stuff you can read in books</li>
</ul>
<p>Robotics manufacturers will provide:</p>
<ul>
<li>observation / perception</li>
<li>actuators</li>
<li>controllers e.g. policies</li>
</ul>
<p>And we’ll use our own expertise to build local states (specific facts about the env) and encode long horizon memories e.g. what did I do 2 years ago.</p>
<hr>
<h3 id="safety-unofficial-in-the-marriott-across-the-road">Safety (unofficial; in the Marriott across the road)</h3>
<p>The safety workshop was wild. It was a small, unofficial congregation of researchers who you’d expect to see lurking on <a href="https://www.lesswrong.com/">Less Wrong</a> and other <a href="https://forum.effectivealtruism.org/">EA forums</a>.</p>
<p><strong><a href="http://christoph-schuhmann.de/">Christoph Schuhmann</a> (Founder of LAION)</strong></p>
<p>Chris is a high school teacher from Vienna; he gave an inspiring talk on the open-sourcing of foundation models. He started LAION (Large-scale Artificial Intelligence Open Network) a non-profit organization, provides datasets, tools and models to democratise ML research. His key points included:</p>
<ul>
<li>centralised intelligence means centralised problem solving; we can’t give the keys to problem solving to a (potentially) dictatorial few.</li>
<li>risks by not open sourcing AI are bigger than those of open sourcing</li>
<li>LAION progress:
<ul>
<li>initial plan was to replicate the orignal CLIP / Dalle-1</li>
<li>got 3m image text pairs on his own</li>
<li>discord server helped him get 300m image text pairs, then 5b pairs</li>
<li>hedge fund gave them 8 A100s</li>
</ul>
</li>
<li>We will always want to do things even if AI can, cause we need to express ourselve</li>
</ul>
<p><strong>Thomas Wolf (Hugging Face CEO)</strong></p>
<p>Tom Wolf gave a talk on the <a href="https://www.notion.so/NeurIPS-a25bdf6d9af045f9bff65177f2833cfa">Big Science initiative</a>, a project takes inspiration from scientific creation schemes such as CERN and the LHC, in which open scientific collaborations facilitate the creation of large-scale artefacts that are useful for the entire research community:</p>
<ul>
<li>1000+ researchers coming together to build massive language model and massive dataset</li>
<li>efficient agi will probs require modularity cc. LeCun</li>
<li>working on the energy efficiency of training is inherently democratic i.e. stops models being held by the rich, especially re: inference</li>
</ul>
<p>Are AI researchers aligned on AGI alignment?</p>
<p>There was interesting round table at the end of the workshop that included <a href="https://scholar.google.com/citations?user=KNr3vb4AAAAJ&amp;hl=en">Jared Kaplan</a> (Anthropic) and <a href="https://scholar.google.ca/citations?user=5Uz70IoAAAAJ&amp;hl=en">David Krueger</a> (Cambridge) discussing what is means to align AGI. There was little agreement.</p>
<hr>
<h2 id="keynotes">Keynotes</h2>
<p>I attended 4 of the 6 keynotes which were:</p>
<ol>
<li><strong>David Chalmers:</strong> <a href="https://nips.cc/virtual/2022/invited-talk/55867">Are Large Language Models Sentient?</a></li>
<li><strong>Emmanuel Candes:</strong> <a href="https://nips.cc/virtual/2022/invited-talk/55872">Conformal Prediction in 2022</a></li>
<li><strong>Isabelle Guyon:</strong> <a href="https://nips.cc/virtual/2022/invited-talk/56158">The Data-Centric Era: How ML is Becoming an Experimental Science</a></li>
<li><strong>Geoff Hinton:</strong> <a href="https://nips.cc/virtual/2022/invited-talk/55869">The Forward-Forward Algorithm for Training Deep Neural Networks</a></li>
</ol>
<p>I found Emmanuel’s talk on conformal prediction enlightening as I’d never heard of the topic (<a href="https://arxiv.org/abs/2107.07511#:~:text=Conformal%20prediction%20is%20a%20user,distributional%20assumptions%20or%20model%20assumptions.">here’s a primer</a>), and Isabelle’s talk on benchmark and data transparency to be agreeable, if a little unoriginal. Hinton’s talk on a more anatomically correct learning algorithm was interesting, but I’m as yet unconvinced that mimicking human intelligence is a good way of building systems that are superior to humans—we are able to leverage hardware for artificial systems far superior to that accessible to humans. Chalmers talk was extremely thought-provoking; he structured the problem of consciousness in LLMs excellently—far better than I’ve seen to date, and as such was my favourite of the four.</p>
<p>I have linked to each of the talks, which are freely available to view above.</p>
<h3 id="references">References</h3>
<p>Fan, L.; Wang, G.; Jiang, Y.; Mandlekar, A.; Yang, Y.; Zhu, H.; Tang, A.; Huang, D.-A.; Zhu, Y.; and Anandkumar, A. 2022. Minedojo: Building open-ended embodied agents with</p>
<p>internet-scale knowledge. Advances in neural information processing systems, 35.</p>
<p>Henaff, M.; Raileanu, R.; Jiang, M.; and Rockt  ̈aschel, T. 2022. Exploration via Elliptical Episodic Bonuses. Advances in neural information processing systems, 35.</p>
<p>Humphreys, P. C.; Guez, A.; Tieleman, O.; Sifre, L.; Weber, T.; and Lillicrap, T. 2022. Large-Scale Retrieval for Reinforcement Learning. Advances in neural information processing systems, 35.</p>
<p>Lee, K.-H.; Nachum, O.; Yang, M.; Lee, L.; Freeman, D.; Xu, W.; Guadarrama, S.; Fischer, I.; Jang, E.; Michalewski, H.; et al. 2022. Multi-game decision transformers. Advances in neural information processing systems, 35.</p>
<p>Paster, K.; McIlraith, S.; and Ba, J. 2022. You Can’t Count on Luck: Why Decision Transformers Fail in Stochastic Environments. Advances in neural information processing systems, 35.</p>
<p>Schaul, T.; Barreto, A.; Quan, J.; and Ostrovski, G. 2022. The phenomenon of policy churn. Advances in neural information processing systems, 35.</p>
<p>Touati, A.; Rapin, J.; and Ollivier, Y. 2022. Does Zero-Shot Reinforcement Learning Exist?</p>

      </div>
    </article>

    <hr />

    <div class="post-info">
      
      

      <p>
        <svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="feather feather-file-text">
          <path d="M14 2H6a2 2 0 0 0-2 2v16a2 2 0 0 0 2 2h12a2 2 0 0 0 2-2V8z"></path>
          <polyline points="14 2 14 8 20 8"></polyline>
          <line x1="16" y1="13" x2="8" y2="13"></line>
          <line x1="16" y1="17" x2="8" y2="17"></line>
          <polyline points="10 9 9 9 8 9"></polyline>
        </svg>
        1779 Words
      </p>

      <p>
        <svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="feather feather-calendar">
          <rect x="3" y="4" width="18" height="18" rx="2" ry="2"></rect>
          <line x1="16" y1="2" x2="16" y2="6"></line>
          <line x1="8" y1="2" x2="8" y2="6"></line>
          <line x1="3" y1="10" x2="21" y2="10"></line>
        </svg>
        
          2023-01-26 21:08
        

         
          
        
      </p>
    </div>
      <hr />
      <div class="sharing-buttons">
        
<a class="resp-sharing-button__link" href="https://facebook.com/sharer/sharer.php?u=https%3a%2f%2fenjeeneer.io%2fposts%2f2023%2f01%2fneurips-2022%2f" target="_blank" rel="noopener" aria-label="" title="Share on facebook">
  <div class="resp-sharing-button resp-sharing-button--facebook resp-sharing-button--small"><div aria-hidden="true" class="resp-sharing-button__icon resp-sharing-button__icon--solid">
    <svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><path d="M18 2h-3a5 5 0 0 0-5 5v3H7v4h3v8h4v-8h3l1-4h-4V7a1 1 0 0 1 1-1h3z"></path></svg>
    </div>
  </div>
</a>


<a class="resp-sharing-button__link" href="https://twitter.com/intent/tweet/?url=https%3a%2f%2fenjeeneer.io%2fposts%2f2023%2f01%2fneurips-2022%2f" target="_blank" rel="noopener" aria-label="" title="Share on twitter">
  <div class="resp-sharing-button resp-sharing-button--twitter resp-sharing-button--small">
      <div aria-hidden="true" class="resp-sharing-button__icon resp-sharing-button__icon--solid">
        <svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><path d="M23 3a10.9 10.9 0 0 1-3.14 1.53 4.48 4.48 0 0 0-7.86 3v1A10.66 10.66 0 0 1 3 4s-4 9 5 13a11.64 11.64 0 0 1-7 2c9 5 20 0 20-11.5a4.5 4.5 0 0 0-.08-.83A7.72 7.72 0 0 0 23 3z"></path></svg>
    </div>
  </div>
</a>


<a class="resp-sharing-button__link" href="https://www.tumblr.com/widgets/share/tool?posttype=link&amp;title=NeurIPS%202022&amp;caption=NeurIPS%202022&amp;canonicalUrl=https%3a%2f%2fenjeeneer.io%2fposts%2f2023%2f01%2fneurips-2022%2f" target="_blank" rel="noopener" aria-label="" title="Share on tumblr">
  <div class="resp-sharing-button resp-sharing-button--tumblr resp-sharing-button--small">
    <div aria-hidden="true" class="resp-sharing-button__icon resp-sharing-button__icon--solid">
      <svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="currentColor" stroke="none" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><path d="M14.563 24c-5.093 0-7.031-3.756-7.031-6.411V9.747H5.116V6.648c3.63-1.313 4.512-4.596 4.71-6.469C9.84.051 9.941 0 9.999 0h3.517v6.114h4.801v3.633h-4.82v7.47c.016 1.001.375 2.371 2.207 2.371h.09c.631-.02 1.486-.205 1.936-.419l1.156 3.425c-.436.636-2.4 1.374-4.156 1.404h-.178l.011.002z"/></svg>
    </div>
  </div>
</a>


<a class="resp-sharing-button__link" href="mailto:?subject=NeurIPS%202022&amp;body=https%3a%2f%2fenjeeneer.io%2fposts%2f2023%2f01%2fneurips-2022%2f" target="_self" rel="noopener" aria-label="" title="Share via email">
  <div class="resp-sharing-button resp-sharing-button--email resp-sharing-button--small"><div aria-hidden="true" class="resp-sharing-button__icon resp-sharing-button__icon--solid">
    <svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><path d="M4 4h16c1.1 0 2 .9 2 2v12c0 1.1-.9 2-2 2H4c-1.1 0-2-.9-2-2V6c0-1.1.9-2 2-2z"></path><polyline points="22,6 12,13 2,6"></polyline></svg>
    </div>
  </div>
</a>


<a class="resp-sharing-button__link" href="https://pinterest.com/pin/create/button/?url=https%3a%2f%2fenjeeneer.io%2fposts%2f2023%2f01%2fneurips-2022%2f&amp;media=https%3a%2f%2fenjeeneer.io%2fposts%2f2023%2f01%2fneurips-2022%2f;description=NeurIPS%202022" target="_blank" rel="noopener" aria-label="" title="Share on pinterest">
  <div class="resp-sharing-button resp-sharing-button--pinterest resp-sharing-button--small"><div aria-hidden="true" class="resp-sharing-button__icon resp-sharing-button__icon--solid">
    <svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="currentColor" stroke="none"><path d="M12.017 0C5.396 0 .029 5.367.029 11.987c0 5.079 3.158 9.417 7.618 11.162-.105-.949-.199-2.403.041-3.439.219-.937 1.406-5.957 1.406-5.957s-.359-.72-.359-1.781c0-1.663.967-2.911 2.168-2.911 1.024 0 1.518.769 1.518 1.688 0 1.029-.653 2.567-.992 3.992-.285 1.193.6 2.165 1.775 2.165 2.128 0 3.768-2.245 3.768-5.487 0-2.861-2.063-4.869-5.008-4.869-3.41 0-5.409 2.562-5.409 5.199 0 1.033.394 2.143.889 2.741.099.12.112.225.085.345-.09.375-.293 1.199-.334 1.363-.053.225-.172.271-.401.165-1.495-.69-2.433-2.878-2.433-4.646 0-3.776 2.748-7.252 7.92-7.252 4.158 0 7.392 2.967 7.392 6.923 0 4.135-2.607 7.462-6.233 7.462-1.214 0-2.354-.629-2.758-1.379l-.749 2.848c-.269 1.045-1.004 2.352-1.498 3.146 1.123.345 2.306.535 3.55.535 6.607 0 11.985-5.365 11.985-11.987C23.97 5.39 18.592.026 11.985.026L12.017 0z"/></svg>
    </div>
  </div>
</a>


<a class="resp-sharing-button__link" href="https://www.linkedin.com/shareArticle?mini=true&amp;url=https%3a%2f%2fenjeeneer.io%2fposts%2f2023%2f01%2fneurips-2022%2f&amp;title=NeurIPS%202022&amp;summary=NeurIPS%202022&amp;source=https%3a%2f%2fenjeeneer.io%2fposts%2f2023%2f01%2fneurips-2022%2f" target="_blank" rel="noopener" aria-label="" title="Share on linkedin">
  <div class="resp-sharing-button resp-sharing-button--linkedin resp-sharing-button--small"><div aria-hidden="true" class="resp-sharing-button__icon resp-sharing-button__icon--solid">
    <svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><path d="M16 8a6 6 0 0 1 6 6v7h-4v-7a2 2 0 0 0-2-2 2 2 0 0 0-2 2v7h-4v-7a6 6 0 0 1 6-6z"></path><rect x="2" y="9" width="4" height="12"></rect><circle cx="4" cy="4" r="2"></circle></svg>
    </div>
  </div>
</a>


<a class="resp-sharing-button__link" href="https://reddit.com/submit/?url=https%3a%2f%2fenjeeneer.io%2fposts%2f2023%2f01%2fneurips-2022%2f&amp;resubmit=true&amp;title=NeurIPS%202022" target="_blank" rel="noopener" aria-label="" title="Share on reddit">
  <div class="resp-sharing-button resp-sharing-button--reddit resp-sharing-button--small"><div aria-hidden="true" class="resp-sharing-button__icon resp-sharing-button__icon--solid">
    <svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="currentColor" stroke="none"><path d="M12 0A12 12 0 0 0 0 12a12 12 0 0 0 12 12 12 12 0 0 0 12-12A12 12 0 0 0 12 0zm5.01 4.744c.688 0 1.25.561 1.25 1.249a1.25 1.25 0 0 1-2.498.056l-2.597-.547-.8 3.747c1.824.07 3.48.632 4.674 1.488.308-.309.73-.491 1.207-.491.968 0 1.754.786 1.754 1.754 0 .716-.435 1.333-1.01 1.614a3.111 3.111 0 0 1 .042.52c0 2.694-3.13 4.87-7.004 4.87-3.874 0-7.004-2.176-7.004-4.87 0-.183.015-.366.043-.534A1.748 1.748 0 0 1 4.028 12c0-.968.786-1.754 1.754-1.754.463 0 .898.196 1.207.49 1.207-.883 2.878-1.43 4.744-1.487l.885-4.182a.342.342 0 0 1 .14-.197.35.35 0 0 1 .238-.042l2.906.617a1.214 1.214 0 0 1 1.108-.701zM9.25 12C8.561 12 8 12.562 8 13.25c0 .687.561 1.248 1.25 1.248.687 0 1.248-.561 1.248-1.249 0-.688-.561-1.249-1.249-1.249zm5.5 0c-.687 0-1.248.561-1.248 1.25 0 .687.561 1.248 1.249 1.248.688 0 1.249-.561 1.249-1.249 0-.687-.562-1.249-1.25-1.249zm-5.466 3.99a.327.327 0 0 0-.231.094.33.33 0 0 0 0 .463c.842.842 2.484.913 2.961.913.477 0 2.105-.056 2.961-.913a.361.361 0 0 0 .029-.463.33.33 0 0 0-.464 0c-.547.533-1.684.73-2.512.73-.828 0-1.979-.196-2.512-.73a.326.326 0 0 0-.232-.095z"/></svg>
    </div>
  </div>
</a>


<a class="resp-sharing-button__link" href="https://www.xing.com/app/user?op=share;url=https%3a%2f%2fenjeeneer.io%2fposts%2f2023%2f01%2fneurips-2022%2f;title=NeurIPS%202022" target="_blank" rel="noopener" aria-label="" title="Share on xing">
  <div class="resp-sharing-button resp-sharing-button--xing resp-sharing-button--small"><div aria-hidden="true" class="resp-sharing-button__icon resp-sharing-button__icon--solid">
    <svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="currentColor" stroke="none"><path d="M18.188 0c-.517 0-.741.325-.927.66 0 0-7.455 13.224-7.702 13.657.015.024 4.919 9.023 4.919 9.023.17.308.436.66.967.66h3.454c.211 0 .375-.078.463-.22.089-.151.089-.346-.009-.536l-4.879-8.916c-.004-.006-.004-.016 0-.022L22.139.756c.095-.191.097-.387.006-.535C22.056.078 21.894 0 21.686 0h-3.498zM3.648 4.74c-.211 0-.385.074-.473.216-.09.149-.078.339.02.531l2.34 4.05c.004.01.004.016 0 .021L1.86 16.051c-.099.188-.093.381 0 .529.085.142.239.234.45.234h3.461c.518 0 .766-.348.945-.667l3.734-6.609-2.378-4.155c-.172-.315-.434-.659-.962-.659H3.648v.016z"/></svg>
    </div>
  </div>
</a>


<a class="resp-sharing-button__link" href="whatsapp://send?text=NeurIPS%202022%20https%3a%2f%2fenjeeneer.io%2fposts%2f2023%2f01%2fneurips-2022%2f" target="_blank" rel="noopener" aria-label="" title="Share on whatsapp">
  <div class="resp-sharing-button resp-sharing-button--whatsapp resp-sharing-button--small"><div aria-hidden="true" class="resp-sharing-button__icon resp-sharing-button__icon--solid">
    <svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="currentColor" stroke="none" stroke-width="1" stroke-linecap="round" stroke-linejoin="round"><path d="M17.472 14.382c-.297-.149-1.758-.867-2.03-.967-.273-.099-.471-.148-.67.15-.197.297-.767.966-.94 1.164-.173.199-.347.223-.644.075-.297-.15-1.255-.463-2.39-1.475-.883-.788-1.48-1.761-1.653-2.059-.173-.297-.018-.458.13-.606.134-.133.298-.347.446-.52.149-.174.198-.298.298-.497.099-.198.05-.371-.025-.52-.075-.149-.669-1.612-.916-2.207-.242-.579-.487-.5-.669-.51-.173-.008-.371-.01-.57-.01-.198 0-.52.074-.792.372-.272.297-1.04 1.016-1.04 2.479 0 1.462 1.065 2.875 1.213 3.074.149.198 2.096 3.2 5.077 4.487.709.306 1.262.489 1.694.625.712.227 1.36.195 1.871.118.571-.085 1.758-.719 2.006-1.413.248-.694.248-1.289.173-1.413-.074-.124-.272-.198-.57-.347m-5.421 7.403h-.004a9.87 9.87 0 01-5.031-1.378l-.361-.214-3.741.982.998-3.648-.235-.374a9.86 9.86 0 01-1.51-5.26c.001-5.45 4.436-9.884 9.888-9.884 2.64 0 5.122 1.03 6.988 2.898a9.825 9.825 0 012.893 6.994c-.003 5.45-4.437 9.884-9.885 9.884m8.413-18.297A11.815 11.815 0 0012.05 0C5.495 0 .16 5.335.157 11.892c0 2.096.547 4.142 1.588 5.945L.057 24l6.305-1.654a11.882 11.882 0 005.683 1.448h.005c6.554 0 11.89-5.335 11.893-11.893a11.821 11.821 0 00-3.48-8.413Z"/></svg>
    </div>
  </div>
</a>


<a class="resp-sharing-button__link" href="https://news.ycombinator.com/submitlink?u=https%3a%2f%2fenjeeneer.io%2fposts%2f2023%2f01%2fneurips-2022%2f&amp;t=NeurIPS%202022" target="_blank" rel="noopener" aria-label="" title="Share on hacker news">
  <div class="resp-sharing-button resp-sharing-button--hackernews resp-sharing-button--small"><div aria-hidden="true" class="resp-sharing-button__icon resp-sharing-button__icon--solid">
			<svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="currentColor" stroke="none"><path d="M0 24V0h24v24H0zM6.951 5.896l4.112 7.708v5.064h1.583v-4.972l4.148-7.799h-1.749l-2.457 4.875c-.372.745-.688 1.434-.688 1.434s-.297-.708-.651-1.434L8.831 5.896h-1.88z"/></svg>
    </div>
  </div>
</a>


<a class="resp-sharing-button__link" href="https://telegram.me/share/url?text=NeurIPS%202022&amp;url=https%3a%2f%2fenjeeneer.io%2fposts%2f2023%2f01%2fneurips-2022%2f" target="_blank" rel="noopener" aria-label="" title="Share on telegram">
  <div class="resp-sharing-button resp-sharing-button--telegram resp-sharing-button--small"><div aria-hidden="true" class="resp-sharing-button__icon resp-sharing-button__icon--solid">
      <svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><line x1="22" y1="2" x2="11" y2="13"></line><polygon points="22 2 15 22 11 13 2 9 22 2"></polygon></svg>
    </div>
  </div>
</a>

      </div>

    


    

  </main>

            </div>

            
        </div>

        




<script type="text/javascript" src="https://enjeeneer.io/bundle.min.a0f363fdf81cdc5cfacc447a79c33189eb000d090336cd04aac8ee256f423b3133b836c281944c19c75e38d0b0b449f01ce5807e37798b7ac94ac1db51983fc4.js" integrity="sha512-oPNj/fgc3Fz6zER6ecMxiesADQkDNs0EqsjuJW9COzEzuDbCgZRMGcdeONCwtEnwHOWAfjd5i3rJSsHbUZg/xA=="></script>
    
<script type="application/javascript">
var doNotTrack = false;
if (!doNotTrack) {
	(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
	(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
	m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
	})(window,document,'script','https://www.google-analytics.com/analytics.js','ga');
	ga('create', 'UA-192648932-1', 'auto');
	
	ga('send', 'pageview');
}
</script>



    </body>
</html>
